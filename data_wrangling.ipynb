{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bill10/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: FutureWarning: The pandas.parser module is deprecated and will be removed in a future version. Please import from pandas.io.parser instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from pandas.parser import CParserError\n",
    "import sys\n",
    "import csv\n",
    "import scipy.sparse as ssp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Article Pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic edit information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the edit information extracted by parsers and generate a table where each row corresponds to an edit and \n",
    "there are 4 columns:\n",
    "1. page title \n",
    "2. time\n",
    "3. editor name\n",
    "4. current page length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Liberal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tarfile.open('liberal.tar.gz') as tar:\n",
    "    tar.extractall('temp/')\n",
    "\n",
    "dfs=[]\n",
    "for i in glob.glob('temp/*.7z'):\n",
    "    subprocess.call(['7z','e',i,'-otemp'])\n",
    "    try:\n",
    "        df=pd.read_csv(i[:-3], sep='|', parse_dates=[0], names=['time','user','byte'],usecols=[0,1,2])\n",
    "        a=pd.to_datetime(df['time'])\n",
    "    except:\n",
    "        subprocess.call(\"tr -d '\\r' < \"+ i[:-3]+ \" > \" + i[:-7], shell=True)\n",
    "        df=pd.read_csv(i[:-7], sep='|', parse_dates=[0], names=['time','user','byte'],usecols=[0,1,2])\n",
    "    df['byte']=pd.to_numeric(df['byte'].str.replace('bytes','').str.strip('() ').str.replace(',','').str.replace('empty','').str.replace('byte',''))\n",
    "    df['title']=i.split('/')[-1][:-15].replace('_',' ')\n",
    "    dfs.append(df)\n",
    "\n",
    "df=pd.concat(dfs,ignore_index=True)\n",
    "\n",
    "df.to_csv('Data/liberal_pages.tsv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conservative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tarfile.open('conservative.tar.gz') as tar:\n",
    "    tar.extractall('temp/')\n",
    "\n",
    "dfs=[]\n",
    "for i in glob.glob('temp/*.7z'):\n",
    "    subprocess.call(['7z','e',i,'-o..temp'])\n",
    "    try:\n",
    "        df=pd.read_csv(i[:-3], sep='|', parse_dates=[0], names=['time','user','byte'],usecols=[0,1,2])\n",
    "        a=pd.to_datetime(df['time'])\n",
    "    except:\n",
    "        subprocess.call(\"tr -d '\\r' < \"+ i[:-3]+ \" > \" + i[:-7], shell=True)\n",
    "        df=pd.read_csv(i[:-7], sep='|', parse_dates=[0], names=['time','user','byte'],usecols=[0,1,2])\n",
    "    df['byte']=pd.to_numeric(df['byte'].str.replace('bytes','').str.strip('() ').str.replace(',','').str.replace('empty','').str.replace('byte',''))\n",
    "    df['title']=i.split('/')[-1][:-15].replace('_',' ')\n",
    "    dfs.append(df)\n",
    "\n",
    "df=pd.concat(dfs,ignore_index=True)\n",
    "\n",
    "df.to_csv('Data/conservative_pages.tsv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Social issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tarfile.open('social_issue_pages.tar.gz') as tar:\n",
    "    tar.extractall('temp/')\n",
    "\n",
    "dfs=[pd.read_csv(i, sep='\\t') for i in glob.glob('temp/*')]\n",
    "\n",
    "df=pd.concat(dfs,ignore_index=True)\n",
    "\n",
    "df.to_csv('Data/social_issue_pages2.tsv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tarfile.open('science_pages.tar.gz') as tar:\n",
    "    tar.extractall('temp/')\n",
    "\n",
    "dfs=[pd.read_csv(i, sep='\\t', parse_dates=[1]) for i in glob.glob('temp/*')]\n",
    "\n",
    "df=pd.concat(dfs,ignore_index=True)\n",
    "\n",
    "df.to_csv('Data/science_pages.tsv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tarfile.open('../Data/social_issue_quality.tar.gz') as tar:\n",
    "    tar.extractall('../Data/temp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfs=[pd.read_csv(i, sep='\\t') for i in glob.glob('../Data/temp/*')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.concat(dfs,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('../Data/social_issue_quality3.tsv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All 3 corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tarfile.open('article_tfidf.tar.gz') as tar:\n",
    "    tar.extractall('temp/')\n",
    "\n",
    "dfs=[pd.read_csv(i, sep='\\t') for i in glob.glob('temp/*')]\n",
    "df=pd.concat(dfs,ignore_index=True)\n",
    "\n",
    "df=df.dropna()\n",
    "df['freq']=pd.to_numeric(df['freq'])\n",
    "\n",
    "x=set(df['title'])\n",
    "title2id=dict(zip(x,xrange(len(x))))\n",
    "id2title=np.array(list(x))\n",
    "\n",
    "x=set(df['word'])\n",
    "word2id=dict(zip(x,xrange(len(x))))\n",
    "\n",
    "row=df['title'].map(lambda x: title2id[x])\n",
    "col=df['word'].map(lambda x: word2id[x])\n",
    "\n",
    "A=ssp.csr_matrix((df['freq'],(row,col)), shape=[len(title2id), len(word2id)])\n",
    "d=(A>0).sum(axis=0)\n",
    "d=d.A.flatten()\n",
    "d=np.log(A.shape[0])-np.log(d)\n",
    "A=A*ssp.diags(d)\n",
    "r=A.sum(axis=1)\n",
    "r=r.A.flatten()\n",
    "tfidf=pd.DataFrame({'id':xrange(A.shape[0]),'tfidf':r})\n",
    "tfidf['title']=tfidf['id'].map(lambda x: id2title[x])\n",
    "\n",
    "tfidf.to_csv('Data/article_tfidf.tsv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Word radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tarfile.open('article_radius.tar.gz') as tar:\n",
    "    tar.extractall('temp/')\n",
    "\n",
    "dfs=[pd.read_csv(i, sep='\\t') for i in glob.glob('temp/*')]\n",
    "\n",
    "df=pd.concat(dfs,ignore_index=True)\n",
    "\n",
    "df.to_csv('Data/article_radius.tsv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Talk Pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each combined table contains information for all the 3 corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic edit information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tarfile.open('Data/talk_pages.tar.gz') as tar:\n",
    "    tar.extractall('temp/')\n",
    "\n",
    "dfs=[pd.read_csv(i, sep='\\t', parse_dates=[1]) for i in glob.glob('temp/*')]\n",
    "\n",
    "df=pd.concat(dfs,ignore_index=True)\n",
    "\n",
    "df.to_csv('../Data/talk_pages3.tsv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tarfile.open('talk_page_tfidf3.tar.gz') as tar:\n",
    "    tar.extractall('temp/')\n",
    "\n",
    "dfs=[pd.read_csv(i, sep='\\t') for i in glob.glob('temp/*')]\n",
    "df=pd.concat(dfs,ignore_index=True)\n",
    "\n",
    "df=df.dropna()\n",
    "df['freq']=pd.to_numeric(df['freq'])\n",
    "\n",
    "x=set(df['title'])\n",
    "title2id=dict(zip(list(x),xrange(len(x))))\n",
    "id2title=np.array(list(x))\n",
    "\n",
    "x=set(df['word'])\n",
    "word2id=dict(zip(list(x),xrange(len(x))))\n",
    "\n",
    "row=df['title'].map(lambda x: title2id[x])\n",
    "col=df['word'].map(lambda x: word2id[x])\n",
    "\n",
    "A=ssp.csr_matrix((df['freq'],(row,col)), shape=[len(title2id), len(word2id)])\n",
    "d=(A>0).sum(axis=0)\n",
    "d=d.A.flatten()\n",
    "d=np.log(A.shape[0])-np.log(d)\n",
    "A=A*ssp.diags(d)\n",
    "r=A.sum(axis=1)\n",
    "r=r.A.flatten()\n",
    "tfidf=pd.DataFrame({'id':xrange(A.shape[0]),'tfidf':r})\n",
    "tfidf['title']=tfidf['id'].map(lambda x: id2title[x])\n",
    "del tfidf['id']\n",
    "\n",
    "tfidf.to_csv('Data/talk_page_tfidf3.tsv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tarfile.open('talk_page_policy3.tar.gz') as tar:\n",
    "    tar.extractall('temp/')\n",
    "\n",
    "dfs=[pd.read_csv(i, sep='\\t') for i in glob.glob('temp/*')]\n",
    "\n",
    "df=pd.concat(dfs,ignore_index=True)\n",
    "\n",
    "df.to_csv('Data/talk_page_policy.tsv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attack score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tarfile.open('talk_page_attack.tar.gz') as tar:\n",
    "    tar.extractall('temp/')\n",
    "\n",
    "dfs=[pd.read_csv(i, sep='\\t') for i in glob.glob('temp/*')]\n",
    "df=pd.concat(dfs,ignore_index=True)\n",
    "\n",
    "df2=df.groupby('title').median()\n",
    "\n",
    "df2=df2.reset_index()\n",
    "\n",
    "df2.to_csv('Data/talk_page_attack3.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Word radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tarfile.open('talk_page_radius4.tar.gz') as tar:\n",
    "    tar.extractall('temp/')\n",
    "\n",
    "dfs=[pd.read_csv(i, sep='\\t') for i in glob.glob('temp/*')]\n",
    "\n",
    "df=pd.concat(dfs,ignore_index=True)\n",
    "\n",
    "df.to_csv('Data/talk_page_radius4.tsv',sep='\\t',index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "nav_menu": {
    "height": "102px",
    "width": "252px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "191px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
